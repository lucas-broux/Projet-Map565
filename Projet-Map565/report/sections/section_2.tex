\documentclass[../report.tex]{subfiles}

\begin{document}

\par Nous souhaitons désormais estimer les quantiles extrêmes de la distribution de températures, notre objectif étant de déterminer le "risque de canicule" entre le 15 juillet et le 15 aout à Bordeaux.


\subsection{Méthodologie}

% Données.
\par Nous conservons la même base de données que dans la partie précédente, mais nous ne considérons que les données de températures prises entre le 15 juillet et le 15 août de chaque année, afin d'effacer le caractère saisonnier mis en évidence dans la première partie.

% Contexte.
\par Nous supposons ainsi que ces données correspondent à $n$ observations i.i.d. $X_1, ..., X_n$ d'une loi $\mathbb{P}$ inconnue. L'objectif est d'estimer, pour $\alpha \in \left[0, 1 \right]$ proche de 1, le quantile d'ordre $\alpha$ de cette loi. Cela nous donnera la valeur de température qui ne sera pas dépassée - avec un niveau de confiance $\alpha$. Notre mesure de "risque de canicule" sera alors la valeur de $\alpha$ pour laquelle cette température maximale est \SI{30}{\celsius}.

% Méthode.
\par Pour cela, comme mis en évidence dans le cours, nous ne considérons pas de méthodes de type paramétriques ou de quantiles empiriques, mais préférons une approche par domaine d'attraction. Nous supposons ainsi que $X_1, ..., X_n$ sont dans le domaine d'attraction d'une certaine loi max-stable, ce qui d'après le cours implique l'existence de $\xi \in \mathbb{R}$ caractérisant cette loi max-stable sous la forme
\begin{displaymath}
H_{\xi} = 
	\begin{cases}
	e^{- {\left( 1 + \xi x \right)}^{-\frac{1}{\xi}}} &\text{si } \xi \neq 0 \\
	e^{-e^{-x}} &\text{si } \xi = 0
	\end{cases}
\end{displaymath}

\par Nous utilisons et comparons deux estimateurs de $\xi$ : l'estimateur de Hill et l'estimateur de Pickands, puis utilisons la valeur obtenue pour calculer les quantiles voulus en vertu des résultats du cours que nous rappellerons.
\par Nous implémentons en outre la méthode dite "\emph{peak over threshold}" et comparons les résultats obtenus avec les précédentes méthodes.

% Vérification des résultats.
\par En revanche, il est difficile de chercher à vérifier les résultats, sachant que nous ne connaissons pas la loi exacte de $X_1$. Il est donc difficile de proposer un test statistique de vérification, et les résultats que nous obtenons restent spéculatifs.


\subsection{Estimateurs de Hill et Pickands}
\par Nous estimons le paramètre $\xi$ selon les formules suivantes : 
\begin{equation}
  \tag{Estimateur de Hill}
  \hat{\xi}_{n, k \left( n \right)}^{H} = \frac{\sum\limits_{i = n - k \left( n \right) + 1 }^{n} \left( \log \left( X_{\left( i, n \right)} \right) - \log \left( X_{\left( n - k \left( n \right) + 1, n\right)} \right) \right)}{k \left( n \right)}
\end{equation}

et
\begin{equation}
  \tag{Estimateur de Pickands}
  \hat{\xi}_{n, k \left( n \right)}^{P} = \frac{1}{\log \left( 2 \right)} \log \left( \frac{ X_{\left( n - k \left( n \right) + 1, n\right)} - X_{\left( n - 2 k \left( n \right) + 1, n\right)}}{X_{\left( n - 2 k \left( n \right) + 1, n\right)} - X_{\left( n - 4 k \left( n \right) + 1, n\right)}} \right)
\end{equation}

où $X_{\left(i, n \right)}$ correspond à la i-ème plus grande valeur parmi tous les $X_j$.

\par Dans les deux cas, des résultats théoriques montrent que l'estimateur converge en probabilités vers la vraie valeur sous les conditions 
\begin{displaymath}
	\begin{cases}
	k \left( n \right) &\xrightarrow[n \to + \infty]{} + \infty \\
	\frac{k \left( n \right)}{n} &\xrightarrow[n \to + \infty]{} 0
	\end{cases}
\end{displaymath}

\par Il s'agit donc de trouver un compromis entre la valeur de $k$ et celle de $n$. En pratique, nous traçons le graphe de $ \hat{\xi}_{n, k \left( n \right)}$ en fonction de $k$ (la valeur de $n$ est fixée et correspond au nombre d'observations), et nous cherchons une "zone de stabilité" correspondant à la valeur estimée de $\xi$.

\subsection{Méthode \emph{peak over threshold}}

\end{document}